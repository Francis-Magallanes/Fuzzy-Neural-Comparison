{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd056b56e9857212bd9884f0e2a2660a298bcf9573e7151eee99724d64738b7b985",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ce11f34a6e98b7940ddd1de6bba18d8b39c708accd7fa23783d62410ed992f80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# LBYCPF3 Project - Neural Network Portion\n",
    "\n",
    "### by Francis John N Magallanes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "### Preprocessing of the Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"iris_improved.csv\")\n",
    "\n",
    "#INPUT PART\n",
    "#this will select all columns up until petal width column\n",
    "input_df = raw_data.loc[:, :\"petal width\"] \n",
    "\n",
    "#this will convert the dataframe into numpy array\n",
    "input_np = input_df.to_numpy()\n",
    "\n",
    "#OUTPUT PART\n",
    "#this will select the class column\n",
    "output_df = raw_data.loc[:, \"class\":]\n",
    "\n",
    "#this will create three columns for the different possible output of the neural network\n",
    "# 1 0 0  is for the Iris-setosa\n",
    "# 0 1 0 is for the Iris-versicolor\n",
    "# 0 0 1 is for the Iris-virginica\n",
    "output_df[\"first-neuron\"] = np.where(output_df[\"class\"] == \"Iris-setosa\" ,1, 0)\n",
    "output_df[\"second-neuron\"] = np.where(output_df[\"class\"] == \"Iris-versicolor\" ,1, 0)\n",
    "output_df[\"third-neuron\"] = np.where(output_df[\"class\"] == \"Iris-virginica\" ,1, 0)\n",
    "\n",
    "#this will convert the dataframe into numpy array\n",
    "output_np = output_df.loc[:, \"first-neuron\":].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the train data and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_np, output_np, test_size= 0.3)"
   ]
  },
  {
   "source": [
    "### Building of the Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will create a simple multi perceptron model\n",
    "nn_model = Sequential()\n",
    "nn_model.add( Dense(4 , activation = \"relu\" ) ) #first hidden layer with 4 neurons\n",
    "nn_model.add( Dense(3 , activation = \"relu\" ) ) # second hidden layer with 3 neurons\n",
    "nn_model.add( Dense(3 , activation = \"softmax\" )) # output layer with 3 neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model\n",
    "nn_model.compile(loss = \"mean_squared_error\", optimizer = \"adam\", metrics = ['accuracy', 'Precision'])"
   ]
  },
  {
   "source": [
    "### Training the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "history = nn_model.fit(x_train,y_train, epochs = 2000, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot of the loss and the accuracy during the training\n",
    "#for the loss\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r')\n",
    "plt.plot(history.history['val_loss'],'b')\n",
    "\n",
    "# Accuracy Curves\n",
    "plt.plot(history.history['accuracy'],'g')\n",
    "plt.plot(history.history['val_accuracy'],'m')\n",
    "\n",
    "#setting the legend\n",
    "plt.legend(['Training loss', 'Validation Loss', 'Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "\n",
    "#setting the title and axis labels\n",
    "plt.xlabel('Epochs ',fontsize=14)\n",
    "plt.ylabel('Accuracy or Loss',fontsize=14)\n",
    "plt.title('Accuracy and Loss Curves',fontsize=18)\n"
   ]
  },
  {
   "source": [
    "### Saving and Loading of the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the saving of the model\n",
    "nn_model.save(\"nn_model_save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the loading of the saved model\n",
    "nn_model = load_model(\"nn_model_save\")"
   ]
  },
  {
   "source": [
    "### Evaluation of the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset for evaluation will be from the test data \n",
    "results = nn_model.evaluate(x_test,y_test)\n",
    "\n",
    "print(\"MSE: {}\".format(results[0]))\n",
    "print(\"Acurracy {}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will plot the confusion matrix\n",
    "y_pred_cm = np.argmax( nn_model.predict(x_test) , axis = 1) #y-pred into classes (0,1,2)\n",
    "y_test_cm = np.argmax(y_test, axis=1) #y-test into classes (0,1,2)\n",
    "cm = confusion_matrix(y_test_cm, y_pred_cm, normalize= 'true') # generate confusion matrix\n",
    "\n",
    "#display the generated confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "            display_labels=['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'] )\n",
    "disp.plot()"
   ]
  },
  {
   "source": [
    "### Prediction from the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.array([[6.3, 3.3, 6.0,2.5]])\n",
    "print(x_pred)\n",
    "y_pred = nn_model.predict(x_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}